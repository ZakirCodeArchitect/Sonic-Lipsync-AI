# ğŸ¤ Sonic Lip Sync - Gradio App (Google Colab Setup)

This project brings the [Sonic](https://github.com/jixiaozhong/Sonic) lip-sync model into a user-friendly Gradio interface, allowing you to generate realistic lip-synced videos directly in **Google Colab** using Hugging Face models. No local installation required.

---

## ğŸš€ Demo
Launches a `.gradio.live` URL from Colab to interact with the app in your browser.

---

## ğŸ§° Features
- ğŸ”Š Converts images and audio into lip-synced video
- ğŸ¤– Powered by: `Sonic`, `Stable Video Diffusion`, `Whisper-tiny`
- ğŸŒ Hosted in Google Colab with full CUDA and PyTorch support
- ğŸ§  Uses Hugging Face CLI to fetch model checkpoints

---

## âš™ï¸ Setup Instructions (Google Colab)

### ğŸ—‚ï¸ 1. Clone the Project in Colab
```bash
mkdir ai-tools
cd ai-tools
mkdir sonic-lip-sync
cd sonic-lip-sync
git clone https://github.com/jixiaozhong/Sonic.git
cd Sonic
```

### ğŸ—‚ï¸ 2. Install Dependencies
```bash
pip install -r requirements.txt
pip install opencv-python
```

### ğŸ—‚ï¸ 3. Install PyTorch with CUDA 12.6
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
```

### ğŸ—‚ï¸ 2. Install Dependencies
```bash
pip install -r requirements.txt
pip install opencv-python
```

